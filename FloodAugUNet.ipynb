{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fASDIL0tyUXK",
        "outputId": "38aa9d73-5ad4-4392-e74d-3157c4ed8479"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WM8YBj00IKCw",
        "outputId": "8250029a-705b-406a-d9e8-c852ef77b939"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tue Aug 24 15:14:01 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.57.02    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0    39W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KhcQWk-qyxV_"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "from tensorflow.keras import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, Activation, Input, InputLayer, Flatten, Conv2D, AveragePooling2D, MaxPool2D, GlobalAveragePooling2D, SeparableConv2D, Conv1D, Conv3D, GlobalAveragePooling3D, AveragePooling3D, DepthwiseConv2D, Conv2DTranspose, Reshape\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop, Adadelta, Adagrad\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from tensorflow.keras.activations import relu\n",
        "from tensorflow.keras.regularizers import L2\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "\n",
        "from tensorflow_addons.layers import StochasticDepth, GroupNormalization\n",
        "from tensorflow_addons.optimizers import AdamW, RectifiedAdam\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import jaccard_score\n",
        "\n",
        "# import runai.ga.keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4c9TFcmEPQ59",
        "outputId": "6331c9c4-4eb6-4435-c365-614bd92ae9ca"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.6.0'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_3jkVr_TL6iJ"
      },
      "outputs": [],
      "source": [
        "featuress = np.load('/content/drive/MyDrive/Flood/features.npy').astype(np.float32)\n",
        "labelss = np.load('/content/drive/MyDrive/Flood/labels.npy').astype(np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vjFTlXVwNgk_"
      },
      "outputs": [],
      "source": [
        "features = featuress\n",
        "labels = labelss.reshape(labelss.shape[0], 512*512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GWAswo-yNC0P"
      },
      "outputs": [],
      "source": [
        "IMAGE_SIZE = features.shape[1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5l_n0t3bbRbz"
      },
      "outputs": [],
      "source": [
        "class SqueezeAndExcite(tf.keras.layers.Layer):\n",
        "    def __init__(self, n):\n",
        "        super().__init__()\n",
        "        self.n = n\n",
        "\n",
        "    def build(self, input_shape):\n",
        "\n",
        "        self.channels = input_shape[-1]\n",
        "\n",
        "        self.pooling = GlobalAveragePooling2D()\n",
        "        self.dense_1 = Dense(self.n, activation='relu')\n",
        "        self.dense_2 =  Dense(self.channels, activation='sigmoid')\n",
        "\n",
        "    def call(self, x, training=False):\n",
        "\n",
        "        r = self.pooling(x)\n",
        "        r = self.dense_1(r, training=training)\n",
        "        r = self.dense_2(r, training=training)\n",
        "\n",
        "        r = tf.reshape(r, (-1, 1, 1, self.channels))\n",
        "\n",
        "        return x * r\n",
        "    \n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"n\": self.n,\n",
        "            \"channels\": self.channels,\n",
        "            \"pooling\": self.pooling,\n",
        "            \"dense_1\": self.dense_1,\n",
        "            \"dense_2\": self.dense_2\n",
        "        })\n",
        "        return config\n",
        "\n",
        "class ResidualSEBlock(tf.keras.layers.Layer):\n",
        "    def __init__(self, filters, strides=1, activation='swish', survival_prob=1, kernel_regularizer=None,  shortcut='identity', reduction=4):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.filters = filters\n",
        "        self.strides = np.array([strides, strides]) if type(strides) == int else np.array(strides)\n",
        "        self.activation = activation\n",
        "        self.survival_prob = survival_prob\n",
        "        self.kernel_regularizer = kernel_regularizer\n",
        "        self.shortcut = shortcut\n",
        "        self.shortcut_mapping = None\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def build(self, input_shape):\n",
        "\n",
        "        spatial_dim = np.array([input_shape[1], input_shape[2]])\n",
        "        channels = input_shape[-1]\n",
        "\n",
        "        self.batch_norm_1 = BatchNormalization()\n",
        "        self.activation_1 = Activation(self.activation)\n",
        "        self.conv_1 = Conv2D(self.filters//4, 1, padding='same', kernel_regularizer=self.kernel_regularizer)\n",
        "        \n",
        "        self.batch_norm_2 = BatchNormalization()\n",
        "        self.activation_2 = Activation(self.activation)\n",
        "        self.conv_2 =  Conv2D(self.filters//4, 3, strides=self.strides, padding='same', kernel_regularizer=self.kernel_regularizer)\n",
        "\n",
        "        self.batch_norm_3 = BatchNormalization()\n",
        "        self.activation_3 = Activation(self.activation)\n",
        "        self.conv_3 =  Conv2D(self.filters, 1, padding='same', kernel_regularizer=self.kernel_regularizer)\n",
        "\n",
        "        self.squeeze_and_excite = SqueezeAndExcite(self.filters//self.reduction)\n",
        "        \n",
        "        if channels != self.filters or self.strides.prod() != 1: \n",
        "          if self.shortcut == 'identity':\n",
        "            self.projection = AveragePooling2D(pool_size=self.strides, strides=self.strides, padding='same')\n",
        "            self.shortcut_mapping = lambda x : tf.pad(self.projection(x), [[0, 0], [0, 0], [0, 0], [0, self.filters - channels]])\n",
        "          if self.shortcut == 'projection':\n",
        "            self.projection = Conv2D(self.filters, 1, strides=self.strides, padding='same')\n",
        "            self.shortcut_mapping = lambda x : self.projection(x)\n",
        "        else:\n",
        "          self.projection = None\n",
        "          self.shortcut_mapping = lambda x : x\n",
        "        \n",
        "        if self.survival_prob != 1:\n",
        "          self.stochastic_depth = StochasticDepth(self.survival_prob)\n",
        "        else:\n",
        "          self.stochastic_depth = None\n",
        "\n",
        "    def call(self, x, training=False):\n",
        "        \n",
        "        r = self.batch_norm_1(x, training=training)\n",
        "        r = self.activation_1(r)\n",
        "        r = self.conv_1(r, training=training)\n",
        "        \n",
        "        r = self.batch_norm_2(r, training=training)\n",
        "        r = self.activation_2(r)\n",
        "        r = self.conv_2(r, training=training)\n",
        "\n",
        "        r = self.batch_norm_3(r, training=training)\n",
        "        r = self.activation_3(r)\n",
        "        r = self.conv_3(r, training=training)\n",
        "\n",
        "        r = self.squeeze_and_excite(r)\n",
        "\n",
        "        x = self.shortcut_mapping(x)\n",
        "\n",
        "        if self.survival_prob != 1:\n",
        "          return self.stochastic_depth([x, r], training=training)\n",
        "\n",
        "        return x + r\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"filters\": self.filters,\n",
        "            \"strides\": self.strides,\n",
        "            \"activation\": self.activation,\n",
        "            \"survival_prob\": self.survival_prob,\n",
        "            \"kernel_regularizer\": self.kernel_regularizer,\n",
        "            \"shortcut\": self.shortcut,\n",
        "            \"projection\": self.projection,\n",
        "            \"shortcut_mapping\": self.shortcut_mapping,\n",
        "            \"reduction\": self.reduction,\n",
        "            \"batch_norm_1\": self.batch_norm_1,\n",
        "            \"activation_1\": self.activation_1,\n",
        "            \"conv_1\": self.conv_1,\n",
        "            \"batch_norm_2\": self.batch_norm_2,\n",
        "            \"activation_2\": self.activation_2,\n",
        "            \"conv_2\": self.conv_2,\n",
        "            \"batch_norm_3\": self.batch_norm_3,\n",
        "            \"activation_3\": self.activation_3,\n",
        "            \"conv_3\": self.conv_3,\n",
        "            \"squeeze_and_excite\": self.squeeze_and_excite,\n",
        "            \"stochastic_depth\": self.stochastic_depth,\n",
        "        })\n",
        "        return config\n",
        "    \n",
        "class ResidualSEBlockT(tf.keras.layers.Layer):\n",
        "    def __init__(self, filters, strides=1, activation='swish', survival_prob=1, kernel_regularizer=None,  shortcut='identity', reduction=4):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.filters = filters\n",
        "        self.strides = np.array([strides, strides]) if type(strides) == int else np.array(strides)\n",
        "        self.activation = activation\n",
        "        self.survival_prob = survival_prob\n",
        "        self.kernel_regularizer = kernel_regularizer\n",
        "        self.shortcut = shortcut\n",
        "        self.shortcut_mapping = None\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def build(self, input_shape):\n",
        "\n",
        "        spatial_dim = np.array([input_shape[1], input_shape[2]])\n",
        "        channels = input_shape[-1]\n",
        "\n",
        "        self.batch_norm_1 = BatchNormalization()\n",
        "        self.activation_1 = Activation(self.activation)\n",
        "        self.conv_1 = Conv2D(self.filters//4, 1, padding='same', kernel_regularizer=self.kernel_regularizer)\n",
        "        \n",
        "        self.batch_norm_2 = BatchNormalization()\n",
        "        self.activation_2 = Activation(self.activation)\n",
        "        self.conv_2 =  Conv2DTranspose(self.filters//4, 3, strides=self.strides, padding='same', kernel_regularizer=self.kernel_regularizer)\n",
        "\n",
        "        self.batch_norm_3 = BatchNormalization()\n",
        "        self.activation_3 = Activation(self.activation)\n",
        "        self.conv_3 =  Conv2D(self.filters, 1, padding='same', kernel_regularizer=self.kernel_regularizer)\n",
        "\n",
        "        self.squeeze_and_excite = SqueezeAndExcite(self.filters//self.reduction)\n",
        "        \n",
        "        if channels != self.filters or self.strides.prod() != 1: \n",
        "          if self.shortcut == 'identity':\n",
        "            self.projection = AveragePooling2D(pool_size=self.strides, strides=self.strides, padding='same')\n",
        "            self.shortcut_mapping = lambda x : tf.pad(self.projection(x), [[0, 0], [0, 0], [0, 0], [0, self.filters - channels]])\n",
        "          if self.shortcut == 'projection':\n",
        "            self.projection = Conv2DTranspose(self.filters, 1, strides=self.strides, padding='same')\n",
        "            self.shortcut_mapping = lambda x : self.projection(x)\n",
        "        else:\n",
        "          self.shortcut_mapping = lambda x : x\n",
        "        \n",
        "        if self.survival_prob != 1:\n",
        "          self.stochastic_depth = StochasticDepth(self.survival_prob) \n",
        "\n",
        "    def call(self, x, training=False):\n",
        "        \n",
        "        r = self.batch_norm_1(x, training=training)\n",
        "        r = self.activation_1(r)\n",
        "        r = self.conv_1(r, training=training)\n",
        "        \n",
        "        r = self.batch_norm_2(r, training=training)\n",
        "        r = self.activation_2(r)\n",
        "        r = self.conv_2(r, training=training)\n",
        "\n",
        "        r = self.batch_norm_3(r, training=training)\n",
        "        r = self.activation_3(r)\n",
        "        r = self.conv_3(r, training=training)\n",
        "\n",
        "        r = self.squeeze_and_excite(r)\n",
        "\n",
        "        x = self.shortcut_mapping(x)\n",
        "\n",
        "        if self.survival_prob != 1:\n",
        "          return self.stochastic_depth([x, r], training=training)\n",
        "\n",
        "        return x + r\n",
        "\n",
        "class ResidualSEBlock2(tf.keras.layers.Layer):\n",
        "    def __init__(self, filters, strides=1, activation='swish', survival_prob=1, kernel_regularizer=None,  shortcut='identity', reduction=4):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.filters = filters\n",
        "        self.strides = np.array([strides, strides]) if type(strides) == int else np.array(strides)\n",
        "        self.activation = activation\n",
        "        self.survival_prob = survival_prob\n",
        "        self.kernel_regularizer = kernel_regularizer\n",
        "        self.shortcut = shortcut\n",
        "        self.shortcut_mapping = None\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def build(self, input_shape):\n",
        "\n",
        "        spatial_dim = np.array([input_shape[1], input_shape[2]])\n",
        "        channels = input_shape[-1]\n",
        "\n",
        "        self.batch_norm_1 = BatchNormalization()\n",
        "        self.activation_1 = Activation(self.activation)\n",
        "        self.conv_1 = Conv2D(self.filters, 3, strides=self.strides, padding='same', kernel_regularizer=self.kernel_regularizer)\n",
        "\n",
        "        self.batch_norm_3 = BatchNormalization()\n",
        "        self.activation_3 = Activation(self.activation)\n",
        "        self.conv_3 =  Conv2D(self.filters, 3, padding='same', kernel_regularizer=self.kernel_regularizer)\n",
        "\n",
        "        self.squeeze_and_excite = SqueezeAndExcite(self.filters//self.reduction)\n",
        "        \n",
        "        if channels != self.filters or self.strides.prod() != 1: \n",
        "          if self.shortcut == 'identity':\n",
        "            self.projection = AveragePooling2D(pool_size=self.strides, strides=self.strides, padding='same')\n",
        "            self.shortcut_mapping = lambda x : tf.pad(self.projection(x), [[0, 0], [0, 0], [0, 0], [0, self.filters - channels]])\n",
        "          if self.shortcut == 'projection':\n",
        "            self.projection = Conv2D(self.filters, 1, strides=self.strides, padding='same')\n",
        "            self.shortcut_mapping = lambda x : self.projection(x)\n",
        "        else:\n",
        "          self.projection = None\n",
        "          self.shortcut_mapping = lambda x : x\n",
        "        \n",
        "        if self.survival_prob != 1:\n",
        "          self.stochastic_depth = StochasticDepth(self.survival_prob)\n",
        "        else:\n",
        "          self.stochastic_depth = None\n",
        "\n",
        "    def call(self, x, training=False):\n",
        "        \n",
        "        r = self.batch_norm_1(x, training=training)\n",
        "        r = self.activation_1(r)\n",
        "        r = self.conv_1(r, training=training)\n",
        "\n",
        "        r = self.batch_norm_3(r, training=training)\n",
        "        r = self.activation_3(r)\n",
        "        r = self.conv_3(r, training=training)\n",
        "\n",
        "        r = self.squeeze_and_excite(r)\n",
        "\n",
        "        x = self.shortcut_mapping(x)\n",
        "\n",
        "        if self.survival_prob != 1:\n",
        "          return self.stochastic_depth([x, r], training=training)\n",
        "\n",
        "        return x + r\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"filters\": self.filters,\n",
        "            \"strides\": self.strides,\n",
        "            \"activation\": self.activation,\n",
        "            \"survival_prob\": self.survival_prob,\n",
        "            \"kernel_regularizer\": self.kernel_regularizer,\n",
        "            \"shortcut\": self.shortcut,\n",
        "            \"projection\": self.projection,\n",
        "            \"shortcut_mapping\": self.shortcut_mapping,\n",
        "            \"reduction\": self.reduction,\n",
        "            \"batch_norm_1\": self.batch_norm_1,\n",
        "            \"activation_1\": self.activation_1,\n",
        "            \"conv_1\": self.conv_1,\n",
        "            \"batch_norm_2\": self.batch_norm_2,\n",
        "            \"activation_2\": self.activation_2,\n",
        "            \"conv_2\": self.conv_2,\n",
        "            \"batch_norm_3\": self.batch_norm_3,\n",
        "            \"activation_3\": self.activation_3,\n",
        "            \"conv_3\": self.conv_3,\n",
        "            \"squeeze_and_excite\": self.squeeze_and_excite,\n",
        "            \"stochastic_depth\": self.stochastic_depth,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "class ResidualBlock(tf.keras.layers.Layer):\n",
        "    def __init__(self, filters, strides=1, activation='swish', survival_prob=1, kernel_regularizer=None,  shortcut='identity', first=False):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.filters = filters\n",
        "        self.strides = np.array([strides, strides]) if type(strides) == int else np.array(strides)\n",
        "        self.activation = activation\n",
        "        self.survival_prob = survival_prob\n",
        "        self.kernel_regularizer = kernel_regularizer\n",
        "        self.shortcut = shortcut\n",
        "        self.shortcut_mapping = None\n",
        "        self.first = first\n",
        "\n",
        "    def build(self, input_shape):\n",
        "\n",
        "        spatial_dim = np.array([input_shape[1], input_shape[2]])\n",
        "        channels = input_shape[-1]\n",
        "\n",
        "        if not self.first:\n",
        "          self.batch_norm_1 = BatchNormalization()\n",
        "          self.activation_1 = Activation(self.activation)\n",
        "        self.conv_1 = Conv2D(self.filters, 3, strides=self.strides, padding='same', kernel_regularizer=self.kernel_regularizer)\n",
        "        \n",
        "        self.batch_norm_2 = BatchNormalization()\n",
        "        self.activation_2 = Activation(self.activation)\n",
        "        self.conv_2 =  Conv2D(self.filters, 3, padding='same', kernel_regularizer=self.kernel_regularizer)\n",
        "        \n",
        "        if channels != self.filters or self.strides.prod() != 1: \n",
        "          if self.shortcut == 'identity':\n",
        "            self.projection = AveragePooling2D(pool_size=self.strides, strides=self.strides, padding='same')\n",
        "            self.shortcut_mapping = lambda x : tf.pad(self.projection(x), [[0, 0], [0, 0], [0, 0], [0, self.filters - channels]])\n",
        "          if self.shortcut == 'projection':\n",
        "            self.projection = Conv2D(self.filters, 1, strides=self.strides, padding='same')\n",
        "            self.shortcut_mapping = lambda x : self.projection(x)\n",
        "        else:\n",
        "          self.shortcut_mapping = lambda x : x\n",
        "        \n",
        "        if self.survival_prob != 1:\n",
        "          self.stochastic_depth = StochasticDepth(self.survival_prob) \n",
        "\n",
        "    def call(self, x, training=False):\n",
        "        \n",
        "        r = x\n",
        "\n",
        "        if not self.first:\n",
        "          r = self.batch_norm_1(r, training=training)\n",
        "          r = self.activation_1(r)\n",
        "        r = self.conv_1(r, training=training)\n",
        "        \n",
        "        r = self.batch_norm_2(r, training=training)\n",
        "        r = self.activation_2(r)\n",
        "        r = self.conv_2(r, training=training)\n",
        "\n",
        "        x = self.shortcut_mapping(x)\n",
        "\n",
        "        if self.survival_prob != 1:\n",
        "          return self.stochastic_depth([x, r], training=training)\n",
        "\n",
        "        return x + r"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hAcyMz3up9ZC"
      },
      "outputs": [],
      "source": [
        "num_models = 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pS57dQWdLfNc"
      },
      "outputs": [],
      "source": [
        "class Augmentation(tf.keras.layers.Layer):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.flip = tf.keras.layers.RandomFlip()\n",
        "  \n",
        "  def call(self, data, training=False):\n",
        "    if not training:\n",
        "      return data\n",
        "    \n",
        "    x, y = data\n",
        "    rotation = tf.cast(tf.random.uniform((1,))[0] * 4, tf.int32)\n",
        "    \n",
        "    x = tf.image.rot90(x, rotation)\n",
        "    y = tf.image.rot90(y, rotation)\n",
        "\n",
        "    x = self.flip(x)\n",
        "    y = self.flip(y)\n",
        "\n",
        "    return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cb4wcNr7DQHS"
      },
      "outputs": [],
      "source": [
        "def apply_transform(x, rotation, h_flip, v_flip):\n",
        "  x = tf.image.rot90(x, rotation)\n",
        "  if h_flip:\n",
        "    x = tf.image.flip_left_right(x)\n",
        "  if v_flip:\n",
        "    x = tf.image.flip_up_down(x)\n",
        "  return x\n",
        "\n",
        "class Model2(Model):\n",
        "\n",
        "    @tf.function\n",
        "    def train_step(self, data):\n",
        "        \n",
        "        x, y = data\n",
        "\n",
        "        y = tf.expand_dims(y, axis=-1)\n",
        "\n",
        "        X = [x]\n",
        "        Y = [y]\n",
        "        for rotation in range(1, 4):\n",
        "          for h_flip in range(2):\n",
        "            for v_flip in range(2):\n",
        "              X.append(apply_transform(x_train, rotation, h_flip, v_flip))\n",
        "              Y.append(apply_transform(y_train, rotation, h_flip, v_flip))\n",
        "        x = tf.concatenate(X, axis=0)\n",
        "        y = tf.concatenate(Y, axis=0)\n",
        "\n",
        "        y = tf.reshape(y, [-1, 262144])\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            y_pred = self(x, training=True)\n",
        "            loss = self.compiled_loss(y, y_pred, regularization_losses=self.losses)\n",
        "\n",
        "        trainable_vars = self.trainable_variables\n",
        "        gradients = tape.gradient(loss, trainable_vars)\n",
        "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "\n",
        "        self.compiled_metrics.update_state(y, y_pred)\n",
        "\n",
        "        return {m.name: m.result() for m in self.metrics}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZYkkPc9ZGYK"
      },
      "outputs": [],
      "source": [
        "def unet_encoder(n, filters, x, pooling=True, reduce_dim=False):\n",
        "    if reduce_dim:\n",
        "      x = Conv2D(reduce_dim, 3, padding='same')(x)\n",
        "    for i in range(n):\n",
        "        x = ResidualSEBlock(filters)(x)\n",
        "    if pooling:\n",
        "      p = MaxPool2D(padding='same')(x)\n",
        "      return x, p\n",
        "    else:\n",
        "      return x\n",
        "\n",
        "def unet_decoder(n, filters, x, r):\n",
        "    x = Conv2DTranspose(filters, 3, strides=2, padding='same')(x)\n",
        "    x = x + r\n",
        "    for i in range(n):\n",
        "      x = ResidualSEBlock(filters)(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmD5salfZDz-",
        "outputId": "29172fe5-a4a2-430e-df84-ca7f1651625c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 512, 512, 2) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 256, 256, 2)  38          input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 128, 128, 2)  38          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "residual_se_block (ResidualSEBl (None, 128, 128, 16) 428         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "residual_se_block_1 (ResidualSE (None, 128, 128, 16) 540         residual_se_block[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "residual_se_block_2 (ResidualSE (None, 128, 128, 16) 540         residual_se_block_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 64, 64, 16)   0           residual_se_block_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "residual_se_block_3 (ResidualSE (None, 64, 64, 32)   1688        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "residual_se_block_4 (ResidualSE (None, 64, 64, 32)   1880        residual_se_block_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "residual_se_block_5 (ResidualSE (None, 64, 64, 32)   1880        residual_se_block_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "residual_se_block_6 (ResidualSE (None, 64, 64, 32)   1880        residual_se_block_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 32, 32, 32)   0           residual_se_block_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "residual_se_block_7 (ResidualSE (None, 32, 32, 64)   6320        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "residual_se_block_8 (ResidualSE (None, 32, 32, 64)   6960        residual_se_block_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "residual_se_block_9 (ResidualSE (None, 32, 32, 64)   6960        residual_se_block_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "residual_se_block_10 (ResidualS (None, 32, 32, 64)   6960        residual_se_block_9[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "residual_se_block_11 (ResidualS (None, 32, 32, 64)   6960        residual_se_block_10[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 16, 16, 64)   0           residual_se_block_11[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "residual_se_block_12 (ResidualS (None, 16, 16, 128)  24416       max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "residual_se_block_13 (ResidualS (None, 16, 16, 128)  26720       residual_se_block_12[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "residual_se_block_14 (ResidualS (None, 16, 16, 128)  26720       residual_se_block_13[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "residual_se_block_15 (ResidualS (None, 16, 16, 128)  26720       residual_se_block_14[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "residual_se_block_16 (ResidualS (None, 16, 16, 128)  26720       residual_se_block_15[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "residual_se_block_17 (ResidualS (None, 16, 16, 128)  26720       residual_se_block_16[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 128)    0           residual_se_block_17[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "residual_se_block_18 (ResidualS (None, 8, 8, 256)    95936       max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "residual_se_block_19 (ResidualS (None, 8, 8, 256)    104640      residual_se_block_18[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "residual_se_block_20 (ResidualS (None, 8, 8, 256)    104640      residual_se_block_19[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "residual_se_block_21 (ResidualS (None, 8, 8, 256)    104640      residual_se_block_20[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "residual_se_block_22 (ResidualS (None, 8, 8, 256)    104640      residual_se_block_21[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "residual_se_block_23 (ResidualS (None, 8, 8, 256)    104640      residual_se_block_22[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "residual_se_block_24 (ResidualS (None, 8, 8, 256)    104640      residual_se_block_23[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_6 (Conv2DTrans (None, 16, 16, 128)  295040      residual_se_block_24[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_10 (TFOpLa (None, 16, 16, 128)  0           conv2d_transpose_6[0][0]         \n",
            "                                                                 residual_se_block_17[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_3 (Conv2DTrans (None, 32, 32, 64)   73792       residual_se_block_17[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "residual_se_block_47 (ResidualS (None, 16, 16, 128)  26720       tf.__operators__.add_10[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_4 (TFOpLam (None, 32, 32, 64)   0           conv2d_transpose_3[0][0]         \n",
            "                                                                 residual_se_block_11[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "residual_se_block_48 (ResidualS (None, 16, 16, 128)  26720       residual_se_block_47[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "residual_se_block_35 (ResidualS (None, 32, 32, 64)   6960        tf.__operators__.add_4[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTrans (None, 64, 64, 32)   18464       residual_se_block_11[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "residual_se_block_49 (ResidualS (None, 16, 16, 128)  26720       residual_se_block_48[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "residual_se_block_36 (ResidualS (None, 32, 32, 64)   6960        residual_se_block_35[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_1 (TFOpLam (None, 64, 64, 32)   0           conv2d_transpose_1[0][0]         \n",
            "                                                                 residual_se_block_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "residual_se_block_50 (ResidualS (None, 16, 16, 128)  26720       residual_se_block_49[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "residual_se_block_37 (ResidualS (None, 32, 32, 64)   6960        residual_se_block_36[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "residual_se_block_28 (ResidualS (None, 64, 64, 32)   1880        tf.__operators__.add_1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "residual_se_block_51 (ResidualS (None, 16, 16, 128)  26720       residual_se_block_50[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "residual_se_block_38 (ResidualS (None, 32, 32, 64)   6960        residual_se_block_37[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "residual_se_block_29 (ResidualS (None, 64, 64, 32)   1880        residual_se_block_28[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose (Conv2DTranspo (None, 128, 128, 16) 4624        residual_se_block_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "residual_se_block_52 (ResidualS (None, 16, 16, 128)  26720       residual_se_block_51[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "residual_se_block_39 (ResidualS (None, 32, 32, 64)   6960        residual_se_block_38[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "residual_se_block_30 (ResidualS (None, 64, 64, 32)   1880        residual_se_block_29[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add (TFOpLambd (None, 128, 128, 16) 0           conv2d_transpose[0][0]           \n",
            "                                                                 residual_se_block_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_7 (Conv2DTrans (None, 32, 32, 64)   73792       residual_se_block_52[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_11 (TFOpLa (None, 32, 32, 64)   0           residual_se_block_11[0][0]       \n",
            "                                                                 residual_se_block_39[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "residual_se_block_31 (ResidualS (None, 64, 64, 32)   1880        residual_se_block_30[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "residual_se_block_25 (ResidualS (None, 128, 128, 16) 540         tf.__operators__.add[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_12 (TFOpLa (None, 32, 32, 64)   0           conv2d_transpose_7[0][0]         \n",
            "                                                                 tf.__operators__.add_11[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_4 (Conv2DTrans (None, 64, 64, 32)   18464       residual_se_block_39[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_5 (TFOpLam (None, 64, 64, 32)   0           residual_se_block_6[0][0]        \n",
            "                                                                 residual_se_block_31[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "residual_se_block_26 (ResidualS (None, 128, 128, 16) 540         residual_se_block_25[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "residual_se_block_53 (ResidualS (None, 32, 32, 64)   6960        tf.__operators__.add_12[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_6 (TFOpLam (None, 64, 64, 32)   0           conv2d_transpose_4[0][0]         \n",
            "                                                                 tf.__operators__.add_5[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "residual_se_block_27 (ResidualS (None, 128, 128, 16) 540         residual_se_block_26[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "residual_se_block_54 (ResidualS (None, 32, 32, 64)   6960        residual_se_block_53[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "residual_se_block_40 (ResidualS (None, 64, 64, 32)   1880        tf.__operators__.add_6[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTrans (None, 128, 128, 16) 4624        residual_se_block_31[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_2 (TFOpLam (None, 128, 128, 16) 0           residual_se_block_2[0][0]        \n",
            "                                                                 residual_se_block_27[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "residual_se_block_55 (ResidualS (None, 32, 32, 64)   6960        residual_se_block_54[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "residual_se_block_41 (ResidualS (None, 64, 64, 32)   1880        residual_se_block_40[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_3 (TFOpLam (None, 128, 128, 16) 0           conv2d_transpose_2[0][0]         \n",
            "                                                                 tf.__operators__.add_2[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "residual_se_block_56 (ResidualS (None, 32, 32, 64)   6960        residual_se_block_55[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "residual_se_block_42 (ResidualS (None, 64, 64, 32)   1880        residual_se_block_41[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "residual_se_block_32 (ResidualS (None, 128, 128, 16) 540         tf.__operators__.add_3[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "residual_se_block_57 (ResidualS (None, 32, 32, 64)   6960        residual_se_block_56[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_13 (TFOpLa (None, 64, 64, 32)   0           residual_se_block_6[0][0]        \n",
            "                                                                 residual_se_block_31[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "residual_se_block_43 (ResidualS (None, 64, 64, 32)   1880        residual_se_block_42[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "residual_se_block_33 (ResidualS (None, 128, 128, 16) 540         residual_se_block_32[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_8 (Conv2DTrans (None, 64, 64, 32)   18464       residual_se_block_57[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_14 (TFOpLa (None, 64, 64, 32)   0           tf.__operators__.add_13[0][0]    \n",
            "                                                                 residual_se_block_43[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "residual_se_block_34 (ResidualS (None, 128, 128, 16) 540         residual_se_block_33[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_7 (TFOpLam (None, 128, 128, 16) 0           residual_se_block_2[0][0]        \n",
            "                                                                 residual_se_block_27[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_15 (TFOpLa (None, 64, 64, 32)   0           conv2d_transpose_8[0][0]         \n",
            "                                                                 tf.__operators__.add_14[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_5 (Conv2DTrans (None, 128, 128, 16) 4624        residual_se_block_43[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_8 (TFOpLam (None, 128, 128, 16) 0           tf.__operators__.add_7[0][0]     \n",
            "                                                                 residual_se_block_34[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "residual_se_block_58 (ResidualS (None, 64, 64, 32)   1880        tf.__operators__.add_15[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_9 (TFOpLam (None, 128, 128, 16) 0           conv2d_transpose_5[0][0]         \n",
            "                                                                 tf.__operators__.add_8[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "residual_se_block_59 (ResidualS (None, 64, 64, 32)   1880        residual_se_block_58[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "residual_se_block_44 (ResidualS (None, 128, 128, 16) 540         tf.__operators__.add_9[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "residual_se_block_60 (ResidualS (None, 64, 64, 32)   1880        residual_se_block_59[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_16 (TFOpLa (None, 128, 128, 16) 0           residual_se_block_2[0][0]        \n",
            "                                                                 residual_se_block_27[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "residual_se_block_45 (ResidualS (None, 128, 128, 16) 540         residual_se_block_44[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "residual_se_block_61 (ResidualS (None, 64, 64, 32)   1880        residual_se_block_60[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_17 (TFOpLa (None, 128, 128, 16) 0           tf.__operators__.add_16[0][0]    \n",
            "                                                                 residual_se_block_34[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "residual_se_block_46 (ResidualS (None, 128, 128, 16) 540         residual_se_block_45[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_9 (Conv2DTrans (None, 128, 128, 16) 4624        residual_se_block_61[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_18 (TFOpLa (None, 128, 128, 16) 0           tf.__operators__.add_17[0][0]    \n",
            "                                                                 residual_se_block_46[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_19 (TFOpLa (None, 128, 128, 16) 0           conv2d_transpose_9[0][0]         \n",
            "                                                                 tf.__operators__.add_18[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "residual_se_block_62 (ResidualS (None, 128, 128, 16) 540         tf.__operators__.add_19[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "residual_se_block_63 (ResidualS (None, 128, 128, 16) 540         residual_se_block_62[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "residual_se_block_64 (ResidualS (None, 128, 128, 16) 540         residual_se_block_63[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 128, 128, 16) 64          residual_se_block_64[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 128, 128, 16) 0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_10 (Conv2DTran (None, 256, 256, 1)  145         activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_11 (Conv2DTran (None, 512, 512, 1)  10          conv2d_transpose_10[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 512, 512, 1)  10          conv2d_transpose_11[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 262144)       0           conv2d_2[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 1,700,565\n",
            "Trainable params: 1,685,921\n",
            "Non-trainable params: 14,644\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "factor = 4\n",
        "\n",
        "x = inp_x = Input(IMAGE_SIZE)\n",
        "\n",
        "# y = inp_y = Input((512, 512))\n",
        "# y = tf.expand_dims(y, axis=-1)\n",
        "\n",
        "# x, y = RandomAugmentation()([x, y])\n",
        "\n",
        "# y = tf.reshape(y, [-1, 262144])\n",
        "\n",
        "x = Conv2D(2, 3, strides=2, padding='same')(x)\n",
        "x = Conv2D(2, 3, strides=2, padding='same')(x)\n",
        "\n",
        "x00, p00 = unet_encoder(3, int(64/factor), x)\n",
        "x10, p10 = unet_encoder(4, int(128/factor), p00)\n",
        "x20, p20 = unet_encoder(5, int(256/factor), p10)\n",
        "x30, p30 = unet_encoder(6, int(512/factor), p20)\n",
        "\n",
        "x40 = unet_encoder(7, int(1024/factor), p30, pooling=False)\n",
        "\n",
        "x01 = unet_decoder(3, int(64/factor), x10, x00)\n",
        "\n",
        "x11 = unet_decoder(4, int(128/factor), x20, x10)\n",
        "\n",
        "x02 = unet_decoder(3, int(64/factor), x11, x00 + x01)\n",
        "\n",
        "x21 = unet_decoder(5, int(256/factor), x30, x20)\n",
        "\n",
        "x12 = unet_decoder(4, int(128/factor), x21, x10 + x11)\n",
        "\n",
        "x03 = unet_decoder(3, int(64/factor), x12, x00 + x01 + x02)\n",
        "\n",
        "x31 = unet_decoder(6, int(512/factor), x40, x30)\n",
        "\n",
        "x22 = unet_decoder(5, int(256/factor), x31, x20 + x21)\n",
        "\n",
        "x13 = unet_decoder(4, int(128/factor), x22, x10 + x11 + x12)\n",
        "\n",
        "x04 = unet_decoder(3, int(64/factor), x13, x00 + x01 + x02 + x03)\n",
        "\n",
        "\n",
        "x = x04\n",
        "\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('swish')(x)\n",
        "x = Conv2DTranspose(1, 3, strides=2, padding='same')(x)\n",
        "x = Conv2DTranspose(1, 3, strides=2, padding='same')(x)\n",
        "x = Conv2D(1, 3, activation='sigmoid', padding='same')(x)\n",
        "x = Flatten()(x)\n",
        "\n",
        "models = [Model2(inputs=inp_x, outputs=x)]\n",
        "models[0].summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aloh8bUBN_SO"
      },
      "outputs": [],
      "source": [
        "class AdjustedBinaryCrossentropy(tf.keras.losses.Loss):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.loss = tf.keras.losses.BinaryCrossentropy()\n",
        "\n",
        "  def call(self, y_true, y_pred, sample_weight=None):\n",
        "    mask = tf.cast(y_true != 255, tf.float32)\n",
        "    y_true = y_true * mask\n",
        "    y_pred = y_pred * mask\n",
        "    return self.loss(y_true, y_pred, sample_weight=sample_weight)\n",
        "\n",
        "class LogCoshDice(tf.keras.losses.Loss):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    # self.loss = tf.keras.losses.LogCosh()\n",
        "\n",
        "  def call(self, y_true, y_pred, sample_weight=None):\n",
        "    mask = tf.cast(y_true != 255, tf.float32)\n",
        "    y_true = y_true * mask\n",
        "    y_pred = y_pred * mask\n",
        "    dice = 1 - tf.reduce_mean((2 * tf.reduce_sum(y_true * y_pred, axis=-1) + 1)/ (tf.reduce_sum(y_true, axis=-1) + tf.reduce_sum(y_pred, axis=-1) + 1))\n",
        "    return tf.math.log(tf.cosh(dice) + 1e-7) \n",
        "\n",
        "class SoftDice(tf.keras.losses.Loss):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    # self.loss = tf.keras.losses.LogCosh()\n",
        "\n",
        "  def call(self, y_true, y_pred, sample_weight=None):\n",
        "    mask = tf.cast(y_true != 255, tf.float32)\n",
        "    y_true = y_true * mask\n",
        "    y_pred = y_pred * mask\n",
        "    return tf.reduce_mean(1 - (2 * tf.reduce_sum(y_true * y_pred, axis=-1) + 1) / (tf.reduce_sum(y_true**2, axis=-1) + tf.reduce_sum(y_pred**2, axis=-1) + 1))\n",
        "\n",
        "class PowerJaccard(tf.keras.losses.Loss):\n",
        "  def __init__(self, p):\n",
        "    super().__init__()\n",
        "    self.p = p\n",
        "\n",
        "  def call(self, y_true, y_pred, sample_weight=None):\n",
        "    mask = tf.cast(y_true != 255, tf.float32)\n",
        "    y_true = y_true * mask\n",
        "    y_pred = y_pred * mask\n",
        "    inter = tf.reduce_sum(y_true * y_pred, axis=-1)\n",
        "    return tf.reduce_mean(1 - (inter + 1e-7)/ (tf.reduce_sum(y_true**self.p, axis=-1) + tf.reduce_sum(y_pred**self.p, axis=-1) - inter + 1e-7))\n",
        "\n",
        "class AdjustedBinaryCrossentropyAndDiceCoeff(tf.keras.losses.Loss):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.loss1 = tf.keras.losses.BinaryCrossentropy()\n",
        "    self.loss2 = LogCoshDice()\n",
        "\n",
        "  def call(self, y_true, y_pred, sample_weight=None):\n",
        "    mask = tf.cast(y_true != 255, tf.float32)\n",
        "    y_true = y_true * mask\n",
        "    y_pred = y_pred * mask\n",
        "    return (self.loss1(y_true, y_pred) + self.loss2(y_true, y_pred)) / 2\n",
        "\n",
        "class AdjustedBinaryCrossentropyAndDiceCoeff2(tf.keras.losses.Loss):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.loss1 = tf.keras.losses.BinaryCrossentropy()\n",
        "    self.loss2 = SoftDice()\n",
        "\n",
        "  def call(self, y_true, y_pred, sample_weight=None):\n",
        "    mask = tf.cast(y_true != 255, tf.float32)\n",
        "    y_true = y_true * mask\n",
        "    y_pred = y_pred * mask\n",
        "    return (self.loss1(y_true, y_pred) + self.loss2(y_true, y_pred)) / 2\n",
        "\n",
        "class AdjustedBinaryCrossentropyAndDiceCoeff3(tf.keras.losses.Loss):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.loss1 = tf.keras.losses.BinaryCrossentropy()\n",
        "\n",
        "  def call(self, y_true, y_pred, sample_weight=None):\n",
        "    mask = tf.cast(y_true != 255, tf.float32)\n",
        "    y_true = y_true * mask\n",
        "    y_pred = y_pred * mask\n",
        "    inter = tf.reduce_sum(y_true * y_pred)\n",
        "    loss2 = inter / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + inter + 1e-7) / (16 * 512 * 512)\n",
        "    return (self.loss1(y_true, y_pred) + loss2) / 2\n",
        "\n",
        "def jaccard(y_true, y_pred):\n",
        "  mask = tf.cast(y_true != 255, tf.float32)\n",
        "  y_true = tf.cast((y_true * mask) > 0.5, tf.float32)\n",
        "  y_pred =  tf.cast((y_pred * mask) > 0.5, tf.float32)\n",
        "  \n",
        "  n_null = tf.reduce_sum(tf.cast(y_true == 255, tf.float32), axis=1)\n",
        "\n",
        "  inter = tf.reduce_sum(tf.cast(y_true == y_pred, tf.float32), axis=1)\n",
        "  return (inter - n_null) / (2*512*512 - inter - n_null)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gteuiDaSpr-5"
      },
      "outputs": [],
      "source": [
        "x_train, y_train = features, labelss\n",
        "y_train2 = y_train.reshape(x_train.shape[0], 512*512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xhFI-c5YJUeD"
      },
      "outputs": [],
      "source": [
        "batch_size = 2\n",
        "decay_epochs = 30\n",
        "epochs = 80"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DYnYCwbMIr9N"
      },
      "outputs": [],
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(batch_size)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train2)).batch(batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgtAjT98EJtp",
        "outputId": "fa3fb5d7-14a7-4d05-9e59-ba2106116797"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/80\n"
          ]
        }
      ],
      "source": [
        "for i, model in enumerate(models):\n",
        "\n",
        "  opt = Adam(tf.keras.optimizers.schedules.ExponentialDecay(0.01, decay_steps=(x_train.shape[0]//batch_size)*decay_epochs, decay_rate=0.1, staircase=True))\n",
        "  loss = AdjustedBinaryCrossentropy()\n",
        "  # loss = LogCoshDice()\n",
        "  # loss = AdjustedBinaryCrossentropyAndDiceCoeff()\n",
        "\n",
        "  model.compile(optimizer=opt, loss=loss, metrics=[jaccard])\n",
        "  model.fit(train_dataset, batch_size=batch_size, epochs=epochs , validation_data=test_dataset)\n",
        "\n",
        "  # model.save(f'/content/drive/MyDrive/Flood/model_{i+1+num_saved}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3fqaQZk16R84"
      },
      "outputs": [],
      "source": [
        "model.save_weights('/content/drive/MyDrive/Flood/model_full_rotation_weights')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NYeu4DRMPyTu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
